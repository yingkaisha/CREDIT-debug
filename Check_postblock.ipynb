{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b17bdd-7fd4-47d8-aec9-2d494eb0fc8b",
   "metadata": {},
   "source": [
    "# Global mass and energy conservations in CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86947d0-a7cf-401a-993e-81dd999c546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from glob import glob\n",
    "from typing import Dict\n",
    "\n",
    "# others\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as tforms\n",
    "\n",
    "# credit\n",
    "from credit.data import (\n",
    "    Sample,\n",
    "    concat_and_reshape,\n",
    "    reshape_only,\n",
    "    ERA5_and_Forcing_Dataset,\n",
    "    get_forward_data\n",
    ")\n",
    "\n",
    "from credit.transforms import (\n",
    "    Normalize_ERA5_and_Forcing,\n",
    "    ToTensor_ERA5_and_Forcing,\n",
    "    load_transforms\n",
    ")\n",
    "\n",
    "from credit.parser import (\n",
    "    CREDIT_main_parser,\n",
    "    training_data_check\n",
    ")\n",
    "\n",
    "from credit.physics_core import physics_pressure_level\n",
    "\n",
    "from credit.physics_constants import (RAD_EARTH, GRAVITY, \n",
    "                                      RHO_WATER, LH_WATER, \n",
    "                                      RVGAS, RDGAS, CP_DRY, CP_VAPOR)\n",
    "\n",
    "from credit.postblock import (\n",
    "    PostBlock,\n",
    "    SKEBS,\n",
    "    tracer_fixer,\n",
    "    global_mass_fixer,\n",
    "    global_energy_fixer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960ef70a-9d5b-4759-9dba-385665d3d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636aa450-27cd-4c6d-86d1-80109ed38790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# single node steup\n",
    "rank = 0\n",
    "world_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1b788-965b-4972-bfdd-5e529cb8b045",
   "metadata": {},
   "source": [
    "## Load yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff02646-f4cf-4ac2-9dcd-8593bdde42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old rollout config\n",
    "# config_name = '/glade/work/ksha/CREDIT_runs/wxformer_6h/model_single.yml'\n",
    "config_name = '/glade/u/home/ksha/miles-physics/config/model_single.yml'\n",
    "# Read YAML file\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60eeef09-6be9-45e2-b877-644c7c050552",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = CREDIT_main_parser(conf, parse_training=True, parse_predict=False, print_summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136a12a-3cc5-4715-a1b6-f5bbf41395b9",
   "metadata": {},
   "source": [
    "## Data workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f6448-9b9c-4398-9ded-d9abfb1ffbac",
   "metadata": {},
   "source": [
    "### Gather data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cb6c52-6bdb-4b5b-b032-8d6490fa8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a year\n",
    "train_years_range = [2018, 2020]\n",
    "valid_years_range = [2018, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a46ff7-16d1-4d17-ae69-c0b55222ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ERA_files = sorted(glob(conf[\"data\"][\"save_loc\"]))\n",
    "\n",
    "# check and glob surface files\n",
    "if ('surface_variables' in conf['data']) and (len(conf['data']['surface_variables']) > 0):\n",
    "    surface_files = sorted(glob(conf[\"data\"][\"save_loc_surface\"]))\n",
    "\n",
    "else:\n",
    "    surface_files = None\n",
    "\n",
    "# check and glob dyn forcing files\n",
    "if ('dynamic_forcing_variables' in conf['data']) and (len(conf['data']['dynamic_forcing_variables']) > 0):\n",
    "    dyn_forcing_files = sorted(glob(conf[\"data\"][\"save_loc_dynamic_forcing\"]))\n",
    "\n",
    "else:\n",
    "    dyn_forcing_files = None\n",
    "\n",
    "# check and glob diagnostic files\n",
    "if ('diagnostic_variables' in conf['data']) and (len(conf['data']['diagnostic_variables']) > 0):\n",
    "    diagnostic_files = sorted(glob(conf[\"data\"][\"save_loc_diagnostic\"]))\n",
    "\n",
    "else:\n",
    "    diagnostic_files = None\n",
    "\n",
    "# convert year info to str for file name search\n",
    "train_years = [str(year) for year in range(train_years_range[0], train_years_range[1])]\n",
    "valid_years = [str(year) for year in range(valid_years_range[0], valid_years_range[1])]\n",
    "\n",
    "# Filter the files for training / validation\n",
    "train_files = [file for file in all_ERA_files if any(year in file for year in train_years)]\n",
    "valid_files = [file for file in all_ERA_files if any(year in file for year in valid_years)]\n",
    "\n",
    "if surface_files is not None:\n",
    "\n",
    "    train_surface_files = [file for file in surface_files if any(year in file for year in train_years)]\n",
    "    valid_surface_files = [file for file in surface_files if any(year in file for year in valid_years)]\n",
    "    \n",
    "else:\n",
    "    train_surface_files = None\n",
    "    valid_surface_files = None\n",
    "\n",
    "if dyn_forcing_files is not None:\n",
    "\n",
    "    train_dyn_forcing_files = [file for file in dyn_forcing_files if any(year in file for year in train_years)]\n",
    "    valid_dyn_forcing_files = [file for file in dyn_forcing_files if any(year in file for year in valid_years)]\n",
    "\n",
    "else:\n",
    "    train_dyn_forcing_files = None\n",
    "    valid_dyn_forcing_files = None\n",
    "\n",
    "if diagnostic_files is not None:\n",
    "\n",
    "    train_diagnostic_files = [file for file in diagnostic_files if any(year in file for year in train_years)]\n",
    "    valid_diagnostic_files = [file for file in diagnostic_files if any(year in file for year in valid_years)]\n",
    "\n",
    "else:\n",
    "    train_diagnostic_files = None\n",
    "    valid_diagnostic_files = None\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "is_train = False\n",
    "# separate training set and validation set cases\n",
    "if is_train:\n",
    "    history_len = conf[\"data\"][\"history_len\"]\n",
    "    forecast_len = conf[\"data\"][\"forecast_len\"]\n",
    "    name = \"training\"\n",
    "else:\n",
    "    history_len = conf[\"data\"][\"valid_history_len\"]\n",
    "    forecast_len = conf[\"data\"][\"valid_forecast_len\"]\n",
    "    name = 'validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b7abb-6cd8-4c8b-a84f-2803d6311421",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84990726-b0eb-4f00-8c6d-4121a6906f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transforms\n",
    "transforms = load_transforms(conf)\n",
    "\n",
    "if conf['data']['sst_forcing']['activate']:\n",
    "    sst_forcing = {'varname_skt': conf['data']['sst_forcing']['varname_skt'], \n",
    "                   'varname_ocean_mask': conf['data']['sst_forcing']['varname_ocean_mask']}\n",
    "else:\n",
    "    sst_forcing = None\n",
    "\n",
    "# Z-score\n",
    "dataset = ERA5_and_Forcing_Dataset(\n",
    "    varname_upper_air=conf['data']['variables'],\n",
    "    varname_surface=conf['data']['surface_variables'],\n",
    "    varname_dyn_forcing=conf['data']['dynamic_forcing_variables'],\n",
    "    varname_forcing=conf['data']['forcing_variables'],\n",
    "    varname_static=conf['data']['static_variables'],\n",
    "    varname_diagnostic=conf['data']['diagnostic_variables'],\n",
    "    filenames=train_files,\n",
    "    filename_surface=train_surface_files,\n",
    "    filename_dyn_forcing=train_dyn_forcing_files,\n",
    "    filename_forcing=conf['data']['save_loc_forcing'],\n",
    "    filename_static=conf['data']['save_loc_static'],\n",
    "    filename_diagnostic=train_diagnostic_files,\n",
    "    history_len=history_len,\n",
    "    forecast_len=forecast_len,\n",
    "    skip_periods=conf[\"data\"][\"skip_periods\"],\n",
    "    one_shot=conf['data']['one_shot'],\n",
    "    max_forecast_len=conf[\"data\"][\"max_forecast_len\"],\n",
    "    transform=transforms,\n",
    "    sst_forcing=sst_forcing\n",
    ")\n",
    "\n",
    "# # sampler\n",
    "# sampler = DistributedSampler(\n",
    "#     dataset,\n",
    "#     num_replicas=world_size,\n",
    "#     rank=rank,\n",
    "#     seed=seed,\n",
    "#     shuffle=is_train,\n",
    "#     drop_last=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596ef12-6f7c-486d-838d-c43ead6b0b45",
   "metadata": {},
   "source": [
    "### An example training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24965281-aad3-40ac-9284-b0bb90441cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_single = dataset.__getitem__(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3f8270-8969-4cce-9e67-28adf61b2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {}\n",
    "keys = list(batch_single.keys())\n",
    "keys = keys[:-1]\n",
    "for var in keys:\n",
    "    batch[var] = batch_single[var].unsqueeze(0) # give a single sample batch dimension\n",
    "\n",
    "# ------------------------- #\n",
    "# base trainer workflow\n",
    "\n",
    "if \"x_surf\" in batch:\n",
    "    # combine x and x_surf\n",
    "    # input: (batch_num, time, var, level, lat, lon), (batch_num, time, var, lat, lon)\n",
    "    # output: (batch_num, var, time, lat, lon), 'x' first and then 'x_surf'\n",
    "    x = concat_and_reshape(batch[\"x\"], batch[\"x_surf\"])\n",
    "else:\n",
    "    # no x_surf\n",
    "    x = reshape_only(batch[\"x\"]).to(self.device).float()\n",
    "\n",
    "# --------------------------------------------------------------------------------- #\n",
    "# add forcing and static variables\n",
    "if 'x_forcing_static' in batch:\n",
    "\n",
    "    # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "    x_forcing_batch = batch['x_forcing_static'].permute(0, 2, 1, 3, 4)\n",
    "\n",
    "    # concat on var dimension\n",
    "    x = torch.cat((x, x_forcing_batch), dim=1)\n",
    "\n",
    "# --------------------------------------------------------------------------------- #\n",
    "# combine y and y_surf\n",
    "if \"y_surf\" in batch:\n",
    "    y = concat_and_reshape(batch[\"y\"], batch[\"y_surf\"])\n",
    "else:\n",
    "    y = reshape_only(batch[\"y\"])\n",
    "\n",
    "if 'y_diag' in batch:\n",
    "\n",
    "    # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "    y_diag_batch = batch['y_diag'].permute(0, 2, 1, 3, 4).float()\n",
    "\n",
    "    # concat on var dimension\n",
    "    y = torch.cat((y, y_diag_batch), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df11bfca-a739-40f2-a932-65a311e44759",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = y.clone()\n",
    "x_original = x.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5538ada-6946-4266-9a69-2b8a4229ca8d",
   "metadata": {},
   "source": [
    "## postblock tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd7414-0bde-4712-85dc-e580a5edb965",
   "metadata": {},
   "source": [
    "### global energy fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760ea883-ae59-418b-a1c1-9217046a5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"y_pred\": y, \"x\": x,}\n",
    "\n",
    "post_conf = conf['model']['post_conf']\n",
    "opt = global_energy_fixer(post_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d965e7d4-0a57-42ef-936a-54093e631ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = opt(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b18781ed-0fa2-4e75-9876-4e59cace817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = output_dict['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bf08d2e-3ea6-4046-b53e-c79dc9dd46dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d98f98e-bfa8-43ac-990d-3c7a03c9975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['x'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a47938e5-d1de-4cc6-92cb-5f1471f27c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_global_energy_fixer_rand():\n",
    "    \n",
    "    # turn-off other blocks\n",
    "    conf = {'post_conf': {'skebs': {'activate': False}}}\n",
    "    conf['post_conf']['tracer_fixer'] = {'activate': False}\n",
    "    conf['post_conf']['global_mass_fixer'] = {'activate': False}\n",
    "    \n",
    "    # energy fixer specs\n",
    "    conf['post_conf']['global_energy_fixer'] = {\n",
    "        'activate': True,\n",
    "        'simple_demo': True,\n",
    "        'denorm': False,\n",
    "        'midpoint': False,\n",
    "        'T_inds': [0, 1, 2, 3, 4, 5, 6],\n",
    "        'q_inds': [0, 1, 2, 3, 4, 5, 6],\n",
    "        'U_inds': [0, 1, 2, 3, 4, 5, 6],\n",
    "        'V_inds': [0, 1, 2, 3, 4, 5, 6],\n",
    "        'TOA_rad_inds': [7, 8],\n",
    "        'surf_rad_inds': [7, 8],\n",
    "        'surf_flux_inds': [7, 8]}\n",
    "    \n",
    "    conf['post_conf']['data'] = {'lead_time_periods': 6}\n",
    "    \n",
    "    # initialize postblock\n",
    "    postblock = PostBlock(**conf)\n",
    "\n",
    "    # verify that global_max_fixer is registered in the postblock\n",
    "    assert any([isinstance(module, global_energy_fixer) for module in postblock.modules()])\n",
    "    \n",
    "    # input tensor\n",
    "    x = torch.randn((1, 7, 2, 10, 18))\n",
    "    # output tensor\n",
    "    y_pred = torch.randn((1, 9, 1, 10, 18))\n",
    "    \n",
    "    input_dict = {\"y_pred\": y_pred, \"x\": x}\n",
    "    # corrected output\n",
    "    y_pred_fix = postblock(input_dict)\n",
    "    \n",
    "    assert y_pred_fix.shape == y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35f857f-9d76-42f6-bccd-0335fb62082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_global_energy_fixer_rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7fa0a-e5b6-4832-b304-666c188cf333",
   "metadata": {},
   "source": [
    "**Check before & after**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0bc350a-6662-49fe-8c7c-11ed6cd9cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_residual_verif(x, y_pred):\n",
    "\n",
    "    state_trans = load_transforms(post_conf, scaler_only=True)\n",
    "    \n",
    "    x = state_trans.inverse_transform_input(x)\n",
    "    y_pred = state_trans.inverse_transform(y_pred)\n",
    "    \n",
    "    N_seconds = 3600 * 6\n",
    "    \n",
    "    T_ind_start = opt.T_ind_start\n",
    "    T_ind_end = opt.T_ind_end\n",
    "    \n",
    "    q_ind_start = opt.q_ind_start\n",
    "    q_ind_end = opt.q_ind_end\n",
    "    \n",
    "    U_ind_start = opt.U_ind_start\n",
    "    U_ind_end = opt.U_ind_end\n",
    "    \n",
    "    V_ind_start = opt.V_ind_start\n",
    "    V_ind_end = opt.V_ind_end\n",
    "    \n",
    "    TOA_solar_ind = opt.TOA_solar_ind\n",
    "    TOA_OLR_ind = opt.TOA_OLR_ind\n",
    "    \n",
    "    surf_solar_ind = opt.surf_solar_ind\n",
    "    surf_LR_ind = opt.surf_LR_ind\n",
    "    \n",
    "    surf_SH_ind = opt.surf_SH_ind\n",
    "    surf_LH_ind = opt.surf_LH_ind\n",
    "\n",
    "    ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "    lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "    lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "    p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "    GPH_surf = torch.from_numpy(ds_physics['geopotential_at_surface'].values)\n",
    "    \n",
    "    core_compute = physics_pressure_level(lon2d, lat2d, p_level, midpoint=False)\n",
    "    \n",
    "    T_input = x[:, T_ind_start:T_ind_end, -1, ...]\n",
    "    q_input = x[:, q_ind_start:q_ind_end, -1, ...]\n",
    "    U_input = x[:, U_ind_start:U_ind_end, -1, ...]\n",
    "    V_input = x[:, V_ind_start:V_ind_end, -1, ...]\n",
    "    \n",
    "    T_pred = y_pred[:, T_ind_start:T_ind_end, 0, ...]\n",
    "    q_pred = y_pred[:, q_ind_start:q_ind_end, 0, ...]\n",
    "    U_pred = y_pred[:, U_ind_start:U_ind_end, 0, ...]\n",
    "    V_pred = y_pred[:, V_ind_start:V_ind_end, 0, ...]\n",
    "            \n",
    "    TOA_solar_pred = y_pred[:, TOA_solar_ind, 0, ...]\n",
    "    TOA_OLR_pred = y_pred[:, TOA_OLR_ind, 0, ...]\n",
    "            \n",
    "    surf_solar_pred = y_pred[:, surf_solar_ind, 0, ...]\n",
    "    surf_LR_pred = y_pred[:, surf_LR_ind, 0, ...]\n",
    "    surf_SH_pred = y_pred[:, surf_SH_ind, 0, ...]\n",
    "    surf_LH_pred = y_pred[:, surf_LH_ind, 0, ...]\n",
    "    \n",
    "    CP_t0 = (1 - q_input) * CP_DRY + q_input * CP_VAPOR\n",
    "    CP_t1 = (1 - q_pred) * CP_DRY + q_pred * CP_VAPOR\n",
    "    \n",
    "    # kinetic energy\n",
    "    ken_t0 = 0.5 * (U_input ** 2 + V_input ** 2)\n",
    "    ken_t1 = 0.5 * (U_pred ** 2 + V_pred ** 2)\n",
    "    \n",
    "    # packing latent heat + potential energy + kinetic energy\n",
    "    E_qgk_t0 = LH_WATER * q_input + GPH_surf + ken_t0\n",
    "    E_qgk_t1 = LH_WATER * q_input + GPH_surf + ken_t1\n",
    "    \n",
    "    # TOA energy flux\n",
    "    R_T = (TOA_solar_pred + TOA_OLR_pred) / N_seconds\n",
    "    R_T_sum = core_compute.weighted_sum(R_T, axis=(-2, -1))\n",
    "    \n",
    "    # surface net energy flux\n",
    "    F_S = (surf_solar_pred + surf_LR_pred + surf_SH_pred + surf_LH_pred) / N_seconds\n",
    "    F_S_sum = core_compute.weighted_sum(F_S, axis=(-2, -1))\n",
    "\n",
    "    E_level_t0 = CP_t0 * T_input + E_qgk_t0\n",
    "    E_level_t1 = CP_t1 * T_pred + E_qgk_t1\n",
    "\n",
    "    # column integrated total energy\n",
    "    TE_t0 = core_compute.integral(E_level_t0) / GRAVITY\n",
    "    TE_t1 = core_compute.integral(E_level_t1) / GRAVITY\n",
    "    \n",
    "    dTE_dt = (TE_t1 - TE_t0) / N_seconds\n",
    "    \n",
    "    dTE_sum = core_compute.weighted_sum(dTE_dt, axis=(1, 2), keepdims=False)\n",
    "    \n",
    "    delta_dTE_sum = (R_T_sum - F_S_sum) - dTE_sum\n",
    "    \n",
    "    print('Residual to conserve energy budget [Watts]: {}'.format(delta_dTE_sum))\n",
    "    return delta_dTE_sum, dTE_sum, (R_T_sum - F_S_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "615449ee-0474-4994-b8fa-42cb97fcf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve energy budget [Watts]: tensor([-8.7528e+14], dtype=torch.float64)\n",
      "Tendency of atmos total energy [Watts]: tensor([-5.5654e+15], dtype=torch.float64)\n",
      "Sources and sinks [Watts]: tensor([-6.4407e+15])\n"
     ]
    }
   ],
   "source": [
    "residual_, tendency_, source_sinks_ = energy_residual_verif(x, y_original)\n",
    "print(f'Tendency of atmos total energy [Watts]: {tendency_}')\n",
    "print(f'Sources and sinks [Watts]: {source_sinks_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e03e8f04-4485-49e8-b332-0e76cdec565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve energy budget [Watts]: tensor([-6.8107e+11], dtype=torch.float64)\n",
      "Tendency of atmos total energy [Watts]: tensor([-6.4400e+15], dtype=torch.float64)\n",
      "Sources and sinks [Watts]: tensor([-6.4407e+15])\n"
     ]
    }
   ],
   "source": [
    "residual_, tendency_, source_sinks_ = energy_residual_verif(x, y_pred)\n",
    "print(f'Tendency of atmos total energy [Watts]: {tendency_}')\n",
    "print(f'Sources and sinks [Watts]: {source_sinks_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bc7ec06-4c5b-4f52-a4a0-d55b895d2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = np.array(y_pred)\n",
    "y_original_np = np.array(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10eeafeb-1d94-42e3-8f01-255626ebdf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 hPa largest modified amount: 0.00025260448455810547\n",
      "2.0 hPa largest modified amount: 0.00023890286684036255\n",
      "3.0 hPa largest modified amount: 0.0002582967281341553\n",
      "5.0 hPa largest modified amount: 0.0003235340118408203\n",
      "7.0 hPa largest modified amount: 0.00036485493183135986\n",
      "10.0 hPa largest modified amount: 0.0004243701696395874\n",
      "20.0 hPa largest modified amount: 0.0005273222923278809\n",
      "30.0 hPa largest modified amount: 0.0005829334259033203\n",
      "50.0 hPa largest modified amount: 0.0006197523325681686\n",
      "70.0 hPa largest modified amount: 0.0005974769592285156\n",
      "100.0 hPa largest modified amount: 0.0006909370422363281\n",
      "125.0 hPa largest modified amount: 0.0007288455963134766\n",
      "150.0 hPa largest modified amount: 0.0006852149963378906\n",
      "175.0 hPa largest modified amount: 0.0005910396575927734\n",
      "200.0 hPa largest modified amount: 0.0005325078964233398\n",
      "225.0 hPa largest modified amount: 0.0005257129669189453\n",
      "250.0 hPa largest modified amount: 0.0005657672882080078\n",
      "300.0 hPa largest modified amount: 0.0007176399230957031\n",
      "350.0 hPa largest modified amount: 0.0007412433624267578\n",
      "400.0 hPa largest modified amount: 0.0007052421569824219\n",
      "450.0 hPa largest modified amount: 0.0006895065307617188\n",
      "500.0 hPa largest modified amount: 0.0007076263427734375\n",
      "550.0 hPa largest modified amount: 0.0007312297821044922\n",
      "600.0 hPa largest modified amount: 0.0007457733154296875\n",
      "650.0 hPa largest modified amount: 0.0007548332214355469\n",
      "700.0 hPa largest modified amount: 0.0007538795471191406\n",
      "750.0 hPa largest modified amount: 0.0007455348968505859\n",
      "775.0 hPa largest modified amount: 0.0007312297821044922\n",
      "800.0 hPa largest modified amount: 0.0007143020629882812\n",
      "825.0 hPa largest modified amount: 0.0006821155548095703\n",
      "850.0 hPa largest modified amount: 0.0006568431854248047\n",
      "875.0 hPa largest modified amount: 0.0006387233734130859\n",
      "900.0 hPa largest modified amount: 0.000621795654296875\n",
      "925.0 hPa largest modified amount: 0.0006103515625\n",
      "950.0 hPa largest modified amount: 0.0005850791931152344\n",
      "975.0 hPa largest modified amount: 0.0005766153335571289\n",
      "1000.0 hPa largest modified amount: 0.0005799531936645508\n"
     ]
    }
   ],
   "source": [
    "T_ind_start = opt.T_ind_start\n",
    "T_ind_end = opt.T_ind_end\n",
    "\n",
    "ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "\n",
    "for i in range(37):\n",
    "    print(f'{p_level[i]/100} hPa largest modified amount: {np.abs(y_pred_np[0, T_ind_start+i, ...] - y_original_np[0, T_ind_start+i, ...]).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a2c721e-bf49-44fc-8c5f-f5383387b09f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(37):\n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(y_pred_np[0, T_ind_start+i, 0, ...], cmap=plt.cm.nipy_spectral_r)\n",
    "#     plt.title('level {}'.format(i))\n",
    "#     plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2c245-d61d-4bee-b57e-1678b314cc00",
   "metadata": {},
   "source": [
    "### global mass fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40730e34-4a96-48fc-a0f3-324c577428a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_dict = {\"y_pred\": y, \"x\": x,}\n",
    "post_conf = conf['model']['post_conf']\n",
    "opt = global_mass_fixer(post_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03a4a588-5a22-4cdf-83ee-ccd3ab96cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = opt(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f49a5fa-08e1-4de0-881d-72b7d963abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = output_dict['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05829847-a958-4104-bfd0-c69ac991ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e3f395f-c8a9-43da-abb6-4d7f724ed3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['x'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2d476-9468-4cd1-aa27-6d3c2f978db0",
   "metadata": {},
   "source": [
    "**test module develop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df9ead48-a8e6-4cf2-a660-d900acec3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_global_mass_fixer_rand():\n",
    "    '''\n",
    "    This function provides a I/O size test on \n",
    "    global_mass_fixer at credit.postblock\n",
    "    '''\n",
    "    # initialize post_conf, turn-off other blocks\n",
    "    conf = {'post_conf': {'skebs': {'activate': False}}}\n",
    "    conf['post_conf']['tracer_fixer'] = {'activate': False}\n",
    "    conf['post_conf']['global_energy_fixer'] = {'activate': False}\n",
    "    \n",
    "    # global mass fixer specs\n",
    "    conf['post_conf']['global_mass_fixer'] = {\n",
    "        'activate': True, \n",
    "        'denorm': False, \n",
    "        'midpoint': False,\n",
    "        'simple_demo': True, \n",
    "        'fix_level_num': 3,\n",
    "        'q_inds': [0, 1, 2, 3, 4, 5, 6],\n",
    "        'precip_ind': 7,\n",
    "        'evapor_ind': 8\n",
    "    }\n",
    "    \n",
    "    # data specs\n",
    "    conf['post_conf']['data'] = {'lead_time_periods': 6}\n",
    "    \n",
    "    # initialize postblock\n",
    "    postblock = PostBlock(**conf)\n",
    "\n",
    "    # verify that global_mass_fixer is registered in the postblock\n",
    "    assert any([isinstance(module, global_mass_fixer) for module in postblock.modules()])\n",
    "    \n",
    "    # input tensor\n",
    "    x = torch.randn((1, 7, 2, 10, 18))\n",
    "    # output tensor\n",
    "    y_pred = torch.randn((1, 9, 1, 10, 18))\n",
    "    \n",
    "    input_dict = {\"y_pred\": y_pred, \"x\": x}\n",
    "    \n",
    "    # corrected output\n",
    "    y_pred_fix = postblock(input_dict)\n",
    "\n",
    "    # verify `y_pred_fix` and `y_pred` has the same size\n",
    "    assert y_pred_fix.shape == y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1fae8a7-2fb2-4292-9472-4fc5a16237c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_global_mass_fixer_rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b7a76-90e4-453a-9326-265e5341f079",
   "metadata": {},
   "source": [
    "**Check before & after**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08530d75-7763-4d99-919c-68b69b74246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_residual_verif(x, y_pred):\n",
    "\n",
    "    state_trans = load_transforms(post_conf, scaler_only=True)\n",
    "    \n",
    "    x = state_trans.inverse_transform_input(x)\n",
    "    y_pred = state_trans.inverse_transform(y_pred)\n",
    "    \n",
    "    precip_ind  = opt.precip_ind\n",
    "    q_ind_start = opt.q_ind_start\n",
    "    q_ind_end = opt.q_ind_end\n",
    "    \n",
    "    ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "    lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "    lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "    p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "    core_compute = physics_pressure_level(lon2d, lat2d, p_level, midpoint=False)\n",
    "    \n",
    "    mass_dry_sum_t0 = core_compute.total_dry_air_mass(x[:, q_ind_start:q_ind_end, -1, ...].unsqueeze(2))\n",
    "    mass_dry_sum_t1 = core_compute.total_dry_air_mass(y_pred[:, q_ind_start:q_ind_end, ...])\n",
    "    mass_residual = mass_dry_sum_t1 - mass_dry_sum_t0\n",
    "    print(f'Residual to conserve energy budget [kg]: {mass_residual}')\n",
    "    return mass_residual, mass_dry_sum_t1, mass_dry_sum_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0184d0e7-6812-4d0f-b127-4c87193c78d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve energy budget [kg]: tensor([[-1.9034e+13]], dtype=torch.float64)\n",
      "Input state total air mass [kg]: tensor([[5.1824e+18]], dtype=torch.float64)\n",
      "Output state total air mass [kg]: tensor([[5.1824e+18]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "residual_, M_t1, M_t0 = mass_residual_verif(x, y_original)\n",
    "print(f'Input state total air mass [kg]: {M_t0}')\n",
    "print(f'Output state total air mass [kg]: {M_t1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52981441-e2ef-49f0-9681-1a1970218964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve energy budget [kg]: tensor([[1.1610e+12]], dtype=torch.float64)\n",
      "Input state total air mass [kg]: tensor([[5.1824e+18]], dtype=torch.float64)\n",
      "Output state total air mass [kg]: tensor([[5.1824e+18]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "residual_, M_t1, M_t0 = mass_residual_verif(x, y_pred)\n",
    "print(f'Input state total air mass [kg]: {M_t0}')\n",
    "print(f'Output state total air mass [kg]: {M_t1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093780c-e49e-42e7-9092-80bc5e3fd34c",
   "metadata": {},
   "source": [
    "**Check modified amount after normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c79c20e-5f31-43b3-b2f2-19c7b2d3c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = np.array(y_pred)\n",
    "y_original_np = np.array(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d5c09f4-1d33-4382-b4b6-8b4bf0c9596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 hPa largest modified amount: 5.364418029785156e-07\n",
      "2.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "3.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "5.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "7.0 hPa largest modified amount: 7.152557373046875e-07\n",
      "10.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "20.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "30.0 hPa largest modified amount: 5.960464477539062e-07\n",
      "50.0 hPa largest modified amount: 7.152557373046875e-07\n",
      "70.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "100.0 hPa largest modified amount: 9.5367431640625e-07\n",
      "125.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "150.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "175.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "200.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "225.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "250.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "300.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "350.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "400.0 hPa largest modified amount: 1.1920928955078125e-07\n",
      "450.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "500.0 hPa largest modified amount: 3.5762786865234375e-07\n",
      "550.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "600.0 hPa largest modified amount: 0.002960294485092163\n",
      "650.0 hPa largest modified amount: 0.002508789300918579\n",
      "700.0 hPa largest modified amount: 0.002169489860534668\n",
      "750.0 hPa largest modified amount: 0.0018903017044067383\n",
      "775.0 hPa largest modified amount: 0.0017962455749511719\n",
      "800.0 hPa largest modified amount: 0.0017227530479431152\n",
      "825.0 hPa largest modified amount: 0.0016801953315734863\n",
      "850.0 hPa largest modified amount: 0.001681506633758545\n",
      "875.0 hPa largest modified amount: 0.001743614673614502\n",
      "900.0 hPa largest modified amount: 0.0018633604049682617\n",
      "925.0 hPa largest modified amount: 0.0020548105239868164\n",
      "950.0 hPa largest modified amount: 0.0023342370986938477\n",
      "975.0 hPa largest modified amount: 0.0025184154510498047\n",
      "1000.0 hPa largest modified amount: 0.002606511116027832\n"
     ]
    }
   ],
   "source": [
    "q_ind_start = opt.q_ind_start\n",
    "q_ind_end = opt.q_ind_end\n",
    "\n",
    "ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "\n",
    "for i in range(37):\n",
    "    print(f'{p_level[i]/100} hPa largest modified amount: {np.abs(y_pred_np[0, q_ind_start+i, ...] - y_original_np[0, q_ind_start+i, ...]).max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee5776-8d46-4405-b4c9-5b9d71d07248",
   "metadata": {},
   "source": [
    "**Check modified q**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e69aeb3-c373-4f59-b68d-a94304cfd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(37):\n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(y_pred_np[0, q_ind_start+i, 0, ...], cmap=plt.cm.nipy_spectral_r)\n",
    "#     plt.title('level {}'.format(i))\n",
    "#     plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838eff7f-0bd1-4b19-96ae-1b22d18771d4",
   "metadata": {},
   "source": [
    "### tracer fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8835544-6fe8-47d3-83fe-b95829e78a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## see test_postblock.py on how it work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
