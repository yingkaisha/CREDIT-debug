{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b17bdd-7fd4-47d8-aec9-2d494eb0fc8b",
   "metadata": {},
   "source": [
    "# Pressure level conservation scheme debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86947d0-a7cf-401a-993e-81dd999c546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from glob import glob\n",
    "from typing import Dict\n",
    "\n",
    "# others\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as tforms\n",
    "\n",
    "# credit\n",
    "from credit.data import (\n",
    "    Sample,\n",
    "    concat_and_reshape,\n",
    "    reshape_only,\n",
    "    ERA5_and_Forcing_Dataset,\n",
    "    get_forward_data\n",
    ")\n",
    "\n",
    "from credit.transforms import (\n",
    "    Normalize_ERA5_and_Forcing,\n",
    "    ToTensor_ERA5_and_Forcing,\n",
    "    load_transforms\n",
    ")\n",
    "\n",
    "from credit.parser import (\n",
    "    credit_main_parser,\n",
    "    training_data_check\n",
    ")\n",
    "\n",
    "from credit.physics_core import physics_pressure_level\n",
    "\n",
    "from credit.physics_constants import (RAD_EARTH, GRAVITY, \n",
    "                                      RHO_WATER, LH_WATER, \n",
    "                                      RVGAS, RDGAS, CP_DRY, CP_VAPOR)\n",
    "\n",
    "from credit.postblock import (\n",
    "    PostBlock,\n",
    "    SKEBS,\n",
    "    TracerFixer,\n",
    "    GlobalMassFixer,\n",
    "    GlobalWaterFixer,\n",
    "    GlobalEnergyFixer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960ef70a-9d5b-4759-9dba-385665d3d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636aa450-27cd-4c6d-86d1-80109ed38790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# single node steup\n",
    "rank = 0\n",
    "world_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1b788-965b-4972-bfdd-5e529cb8b045",
   "metadata": {},
   "source": [
    "## Load yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff02646-f4cf-4ac2-9dcd-8593bdde42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old rollout config\n",
    "# config_name = '/glade/work/ksha/CREDIT_runs/wxformer_6h/model_single.yml'\n",
    "# config_name = '/glade/u/home/ksha/miles-credit/config/example_physics_single.yml'\n",
    "config_name = '/glade/work/ksha/CREDIT_runs/fuxi_w_physics/model_single.yml'\n",
    "# Read YAML file\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60eeef09-6be9-45e2-b877-644c7c050552",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = credit_main_parser(conf, parse_training=True, parse_predict=False, print_summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136a12a-3cc5-4715-a1b6-f5bbf41395b9",
   "metadata": {},
   "source": [
    "## Data workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f6448-9b9c-4398-9ded-d9abfb1ffbac",
   "metadata": {},
   "source": [
    "### Gather data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cb6c52-6bdb-4b5b-b032-8d6490fa8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a year\n",
    "train_years_range = [2018, 2020]\n",
    "valid_years_range = [2018, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a46ff7-16d1-4d17-ae69-c0b55222ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ERA_files = sorted(glob(conf[\"data\"][\"save_loc\"]))\n",
    "\n",
    "# check and glob surface files\n",
    "if ('surface_variables' in conf['data']) and (len(conf['data']['surface_variables']) > 0):\n",
    "    surface_files = sorted(glob(conf[\"data\"][\"save_loc_surface\"]))\n",
    "\n",
    "else:\n",
    "    surface_files = None\n",
    "\n",
    "# check and glob dyn forcing files\n",
    "if ('dynamic_forcing_variables' in conf['data']) and (len(conf['data']['dynamic_forcing_variables']) > 0):\n",
    "    dyn_forcing_files = sorted(glob(conf[\"data\"][\"save_loc_dynamic_forcing\"]))\n",
    "\n",
    "else:\n",
    "    dyn_forcing_files = None\n",
    "\n",
    "# check and glob diagnostic files\n",
    "if ('diagnostic_variables' in conf['data']) and (len(conf['data']['diagnostic_variables']) > 0):\n",
    "    diagnostic_files = sorted(glob(conf[\"data\"][\"save_loc_diagnostic\"]))\n",
    "\n",
    "else:\n",
    "    diagnostic_files = None\n",
    "\n",
    "# convert year info to str for file name search\n",
    "train_years = [str(year) for year in range(train_years_range[0], train_years_range[1])]\n",
    "valid_years = [str(year) for year in range(valid_years_range[0], valid_years_range[1])]\n",
    "\n",
    "# Filter the files for training / validation\n",
    "train_files = [file for file in all_ERA_files if any(year in file for year in train_years)]\n",
    "valid_files = [file for file in all_ERA_files if any(year in file for year in valid_years)]\n",
    "\n",
    "if surface_files is not None:\n",
    "\n",
    "    train_surface_files = [file for file in surface_files if any(year in file for year in train_years)]\n",
    "    valid_surface_files = [file for file in surface_files if any(year in file for year in valid_years)]\n",
    "    \n",
    "else:\n",
    "    train_surface_files = None\n",
    "    valid_surface_files = None\n",
    "\n",
    "if dyn_forcing_files is not None:\n",
    "\n",
    "    train_dyn_forcing_files = [file for file in dyn_forcing_files if any(year in file for year in train_years)]\n",
    "    valid_dyn_forcing_files = [file for file in dyn_forcing_files if any(year in file for year in valid_years)]\n",
    "\n",
    "else:\n",
    "    train_dyn_forcing_files = None\n",
    "    valid_dyn_forcing_files = None\n",
    "\n",
    "if diagnostic_files is not None:\n",
    "\n",
    "    train_diagnostic_files = [file for file in diagnostic_files if any(year in file for year in train_years)]\n",
    "    valid_diagnostic_files = [file for file in diagnostic_files if any(year in file for year in valid_years)]\n",
    "\n",
    "else:\n",
    "    train_diagnostic_files = None\n",
    "    valid_diagnostic_files = None\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "is_train = False\n",
    "# separate training set and validation set cases\n",
    "if is_train:\n",
    "    history_len = conf[\"data\"][\"history_len\"]\n",
    "    forecast_len = conf[\"data\"][\"forecast_len\"]\n",
    "    name = \"training\"\n",
    "else:\n",
    "    history_len = conf[\"data\"][\"valid_history_len\"]\n",
    "    forecast_len = conf[\"data\"][\"valid_forecast_len\"]\n",
    "    name = 'validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b7abb-6cd8-4c8b-a84f-2803d6311421",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84990726-b0eb-4f00-8c6d-4121a6906f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transforms\n",
    "transforms = load_transforms(conf)\n",
    "\n",
    "if conf['data']['sst_forcing']['activate']:\n",
    "    sst_forcing = {'varname_skt': conf['data']['sst_forcing']['varname_skt'], \n",
    "                   'varname_ocean_mask': conf['data']['sst_forcing']['varname_ocean_mask']}\n",
    "else:\n",
    "    sst_forcing = None\n",
    "\n",
    "# Z-score\n",
    "dataset = ERA5_and_Forcing_Dataset(\n",
    "    varname_upper_air=conf['data']['variables'],\n",
    "    varname_surface=conf['data']['surface_variables'],\n",
    "    varname_dyn_forcing=conf['data']['dynamic_forcing_variables'],\n",
    "    varname_forcing=conf['data']['forcing_variables'],\n",
    "    varname_static=conf['data']['static_variables'],\n",
    "    varname_diagnostic=conf['data']['diagnostic_variables'],\n",
    "    filenames=train_files,\n",
    "    filename_surface=train_surface_files,\n",
    "    filename_dyn_forcing=train_dyn_forcing_files,\n",
    "    filename_forcing=conf['data']['save_loc_forcing'],\n",
    "    filename_static=conf['data']['save_loc_static'],\n",
    "    filename_diagnostic=train_diagnostic_files,\n",
    "    history_len=history_len,\n",
    "    forecast_len=forecast_len,\n",
    "    skip_periods=conf[\"data\"][\"skip_periods\"],\n",
    "    one_shot=conf['data']['one_shot'],\n",
    "    max_forecast_len=conf[\"data\"][\"max_forecast_len\"],\n",
    "    transform=transforms,\n",
    "    sst_forcing=sst_forcing\n",
    ")\n",
    "\n",
    "# # sampler\n",
    "# sampler = DistributedSampler(\n",
    "#     dataset,\n",
    "#     num_replicas=world_size,\n",
    "#     rank=rank,\n",
    "#     seed=seed,\n",
    "#     shuffle=is_train,\n",
    "#     drop_last=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596ef12-6f7c-486d-838d-c43ead6b0b45",
   "metadata": {},
   "source": [
    "### An example training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24965281-aad3-40ac-9284-b0bb90441cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_single = dataset.__getitem__(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca3f8270-8969-4cce-9e67-28adf61b2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {}\n",
    "keys = list(batch_single.keys())\n",
    "keys = keys[:-1]\n",
    "for var in keys:\n",
    "    batch[var] = batch_single[var].unsqueeze(0) # give a single sample batch dimension\n",
    "\n",
    "# ------------------------- #\n",
    "# base trainer workflow\n",
    "\n",
    "if \"x_surf\" in batch:\n",
    "    # combine x and x_surf\n",
    "    # input: (batch_num, time, var, level, lat, lon), (batch_num, time, var, lat, lon)\n",
    "    # output: (batch_num, var, time, lat, lon), 'x' first and then 'x_surf'\n",
    "    x = concat_and_reshape(batch[\"x\"], batch[\"x_surf\"])\n",
    "else:\n",
    "    # no x_surf\n",
    "    x = reshape_only(batch[\"x\"]).to(self.device).float()\n",
    "\n",
    "# --------------------------------------------------------------------------------- #\n",
    "# add forcing and static variables\n",
    "if 'x_forcing_static' in batch:\n",
    "\n",
    "    # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "    x_forcing_batch = batch['x_forcing_static'].permute(0, 2, 1, 3, 4)\n",
    "\n",
    "    # concat on var dimension\n",
    "    x = torch.cat((x, x_forcing_batch), dim=1)\n",
    "\n",
    "# --------------------------------------------------------------------------------- #\n",
    "# combine y and y_surf\n",
    "if \"y_surf\" in batch:\n",
    "    y = concat_and_reshape(batch[\"y\"], batch[\"y_surf\"])\n",
    "else:\n",
    "    y = reshape_only(batch[\"y\"])\n",
    "\n",
    "if 'y_diag' in batch:\n",
    "\n",
    "    # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "    y_diag_batch = batch['y_diag'].permute(0, 2, 1, 3, 4).float()\n",
    "\n",
    "    # concat on var dimension\n",
    "    y = torch.cat((y, y_diag_batch), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b83cfb-ea45-40fa-8e90-2c0612f0de8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ceeffe-c626-4551-ae03-8716aacf66d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36.8391)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72140ce3-98f0-4697-98f7-bd75d2b0a52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.6895)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1abfc9-911c-4c85-a101-058762794f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876a9d3-fc08-4e88-a7e9-c3d3d842eeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6908fd64-6c83-450e-880e-90ce8c311923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2000):\n",
    "#     batch_single = dataset.__getitem__(i)\n",
    "\n",
    "#     batch = {}\n",
    "#     keys = list(batch_single.keys())\n",
    "#     keys = keys[:-1]\n",
    "#     for var in keys:\n",
    "#         batch[var] = batch_single[var].unsqueeze(0) # give a single sample batch dimension\n",
    "    \n",
    "#     # ------------------------- #\n",
    "#     # base trainer workflow\n",
    "    \n",
    "#     if \"x_surf\" in batch:\n",
    "#         # combine x and x_surf\n",
    "#         # input: (batch_num, time, var, level, lat, lon), (batch_num, time, var, lat, lon)\n",
    "#         # output: (batch_num, var, time, lat, lon), 'x' first and then 'x_surf'\n",
    "#         x = concat_and_reshape(batch[\"x\"], batch[\"x_surf\"])\n",
    "#     else:\n",
    "#         # no x_surf\n",
    "#         x = reshape_only(batch[\"x\"]).to(self.device).float()\n",
    "    \n",
    "#     # --------------------------------------------------------------------------------- #\n",
    "#     # add forcing and static variables\n",
    "#     if 'x_forcing_static' in batch:\n",
    "    \n",
    "#         # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "#         x_forcing_batch = batch['x_forcing_static'].permute(0, 2, 1, 3, 4)\n",
    "    \n",
    "#         # concat on var dimension\n",
    "#         x = torch.cat((x, x_forcing_batch), dim=1)\n",
    "    \n",
    "#     # --------------------------------------------------------------------------------- #\n",
    "#     # combine y and y_surf\n",
    "#     if \"y_surf\" in batch:\n",
    "#         y = concat_and_reshape(batch[\"y\"], batch[\"y_surf\"])\n",
    "#     else:\n",
    "#         y = reshape_only(batch[\"y\"])\n",
    "    \n",
    "#     if 'y_diag' in batch:\n",
    "    \n",
    "#         # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "#         y_diag_batch = batch['y_diag'].permute(0, 2, 1, 3, 4).float()\n",
    "    \n",
    "#         # concat on var dimension\n",
    "#         y = torch.cat((y, y_diag_batch), dim=1)\n",
    "\n",
    "#     print('{} - {} - {}'.format(\n",
    "#         i, \n",
    "#         y.abs().max(), \n",
    "#         (y.abs()>16).sum()\n",
    "#     )\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df11bfca-a739-40f2-a932-65a311e44759",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = y.clone()\n",
    "x_original = x.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5538ada-6946-4266-9a69-2b8a4229ca8d",
   "metadata": {},
   "source": [
    "## `credit.postblock` tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252a31ca-8378-4d02-acd9-6810ff4667c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from credit.postblock import concat_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de5d11-953c-49a4-8d7b-20a67cc64363",
   "metadata": {},
   "source": [
    "### Global mass fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b67b97-f5c1-43fe-b0e1-2733f498b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"y_pred\": y, \"x\": x,}\n",
    "post_conf = conf['model']['post_conf']\n",
    "opt = GlobalMassFixer(post_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04dcf5a6-3678-4972-b049-8b18a4f1432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    input_dict = opt(input_dict)\n",
    "    \n",
    "y_pred = input_dict['y_pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98a759-0f69-4c72-ae9d-5e90e28607c9",
   "metadata": {},
   "source": [
    "**Check before & after**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fd4182f-4cb3-4d15-863b-d2da64d6b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_residual_verif(x, y_pred):\n",
    "\n",
    "    state_trans = load_transforms(post_conf, scaler_only=True)\n",
    "    \n",
    "    x = state_trans.inverse_transform_input(x)\n",
    "    y_pred = state_trans.inverse_transform(y_pred)\n",
    "    \n",
    "    q_ind_start = opt.q_ind_start\n",
    "    q_ind_end = opt.q_ind_end\n",
    "    \n",
    "    ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "    lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "    lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "    p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "    core_compute = physics_pressure_level(lon2d, lat2d, p_level, midpoint=False)\n",
    "    \n",
    "    mass_dry_sum_t0 = core_compute.total_dry_air_mass(x[:, q_ind_start:q_ind_end, -1, ...].unsqueeze(2))\n",
    "    mass_dry_sum_t1 = core_compute.total_dry_air_mass(y_pred[:, q_ind_start:q_ind_end, ...])\n",
    "    mass_residual = mass_dry_sum_t1 - mass_dry_sum_t0\n",
    "    print(f'Residual to conserve mass budget [kg]: {mass_residual}')\n",
    "    return mass_residual, mass_dry_sum_t1, mass_dry_sum_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb6b0c47-4cb7-4830-8d0b-8226ba394278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== Before ==============================\n",
      "Residual to conserve mass budget [kg]: tensor([[1.6493e+12]])\n",
      "Input state total air mass [kg]: tensor([[5.1832e+18]])\n",
      "Output state total air mass [kg]: tensor([[5.1832e+18]])\n",
      "======================== After ==============================\n",
      "Residual to conserve mass budget [kg]: tensor([[5.4976e+11]])\n",
      "Input state total air mass [kg]: tensor([[5.1832e+18]])\n",
      "Output state total air mass [kg]: tensor([[5.1832e+18]])\n"
     ]
    }
   ],
   "source": [
    "print('======================== Before ==============================')\n",
    "residual_, M_t1, M_t0 = mass_residual_verif(x, y_original)\n",
    "print(f'Input state total air mass [kg]: {M_t0}')\n",
    "print(f'Output state total air mass [kg]: {M_t1}')\n",
    "\n",
    "print('======================== After ==============================')\n",
    "residual_, M_t1, M_t0 = mass_residual_verif(x, y_pred)\n",
    "print(f'Input state total air mass [kg]: {M_t0}')\n",
    "print(f'Output state total air mass [kg]: {M_t1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27ec3031-8a02-4c2a-a902-f46ff33abcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = np.array(y_pred)\n",
    "y_original_np = np.array(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5551dc4-afc3-4ba8-8120-a90c3c7055e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 hPa largest modified amount: 1.6689300537109375e-06\n",
      "50.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "150.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "200.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "250.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "300.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "400.0 hPa largest modified amount: 4.76837158203125e-07\n",
      "500.0 hPa largest modified amount: 2.384185791015625e-07\n",
      "600.0 hPa largest modified amount: 0.0004565715789794922\n",
      "700.0 hPa largest modified amount: 0.0003173351287841797\n",
      "850.0 hPa largest modified amount: 0.00019669532775878906\n",
      "925.0 hPa largest modified amount: 0.00015926361083984375\n",
      "1000.0 hPa largest modified amount: 0.00013637542724609375\n"
     ]
    }
   ],
   "source": [
    "q_ind_start = opt.q_ind_start\n",
    "q_ind_end = opt.q_ind_end\n",
    "\n",
    "ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "\n",
    "for i in range(13):\n",
    "    print(f'{p_level[i]/100} hPa largest modified amount: {np.abs(y_pred_np[0, q_ind_start+i, ...] - y_original_np[0, q_ind_start+i, ...]).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0803c9ad-e023-4854-8843-c7b7436ab0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(37):\n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(y_pred_np[0, q_ind_start+i, 0, ...], cmap=plt.cm.nipy_spectral_r)\n",
    "#     plt.title('level {}'.format(i))\n",
    "#     plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563195c-0e23-49b0-ba8a-960332a51a8b",
   "metadata": {},
   "source": [
    "### Global water fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86e2b63e-e2ec-4b18-b88d-fad54e636ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"y_pred\": y, \"x\": x,}\n",
    "post_conf = conf['model']['post_conf']\n",
    "opt = GlobalWaterFixer(post_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b09f9452-be48-4a3c-ac47-edd34c1ba300",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    input_dict = opt(input_dict)\n",
    "    \n",
    "y_pred = input_dict['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "776d086b-efda-4c2e-8a77-a216861ffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_budget_verif(x, y_pred):\n",
    "\n",
    "    state_trans = load_transforms(post_conf, scaler_only=True)\n",
    "    N_seconds = 3600 * 6\n",
    "    x = state_trans.inverse_transform_input(x)\n",
    "    y_pred = state_trans.inverse_transform(y_pred)\n",
    "    \n",
    "    precip_ind  = opt.precip_ind\n",
    "    q_ind_start = opt.q_ind_start\n",
    "    q_ind_end = opt.q_ind_end\n",
    "    evapor_ind = opt.evapor_ind\n",
    "    \n",
    "    ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "    lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "    lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "    p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "    core_compute = physics_pressure_level(lon2d, lat2d, p_level, midpoint=False)\n",
    "\n",
    "    q_input = x[:, q_ind_start:q_ind_end, -1, ...]\n",
    "    q_pred = y_pred[:, q_ind_start:q_ind_end, 0, ...]\n",
    "    precip = y_pred[:, precip_ind, 0, ...]\n",
    "    evapor = y_pred[:, evapor_ind, 0, ...]\n",
    "\n",
    "    precip_flux = precip * RHO_WATER / N_seconds\n",
    "    evapor_flux = evapor * RHO_WATER / N_seconds\n",
    "    \n",
    "    # total water content (batch, var, time, lat, lon)\n",
    "    TWC_input = core_compute.total_column_water(q_input)\n",
    "    TWC_pred = core_compute.total_column_water(q_pred)\n",
    "        \n",
    "    dTWC_dt = (TWC_pred - TWC_input) / N_seconds\n",
    "    \n",
    "    TWC_sum = core_compute.weighted_sum(dTWC_dt, axis=(-2, -1))\n",
    "    E_sum = core_compute.weighted_sum(evapor_flux, axis=(-2, -1))\n",
    "    P_sum = core_compute.weighted_sum(precip_flux, axis=(-2, -1))\n",
    "        \n",
    "    # global water balance residual\n",
    "    residual = -TWC_sum - E_sum - P_sum\n",
    "    print(f'Residual to conserve water budget [kg]: {residual}')\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0ee556e-1101-4544-bfa9-9539c856df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve water budget [kg]: tensor([-1.0777e+09])\n"
     ]
    }
   ],
   "source": [
    "residual_ = water_budget_verif(x, y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8b4225b-0b65-4b73-abd6-84643282dbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve water budget [kg]: tensor([1024.])\n"
     ]
    }
   ],
   "source": [
    "residual_ = water_budget_verif(x, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eca1ffe6-8314-4ba2-bcd0-5d9dbceb7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precip largest modified amount: 0.6018228530883789\n"
     ]
    }
   ],
   "source": [
    "y_pred_np = np.array(y_pred)\n",
    "y_original_np = np.array(y_original)\n",
    "\n",
    "precip_ind = opt.precip_ind\n",
    "\n",
    "ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "\n",
    "print(f'precip largest modified amount: {np.abs(y_pred_np[0, precip_ind, ...] - y_original_np[0, precip_ind, ...]).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdc9d58d-c95c-4f59-b5a5-a3e149bd02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(37):\n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(y_pred_np[0, q_ind_start+i, 0, ...], cmap=plt.cm.nipy_spectral_r)\n",
    "#     plt.title('level {}'.format(i))\n",
    "#     plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd7414-0bde-4712-85dc-e580a5edb965",
   "metadata": {},
   "source": [
    "### Global energy fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "760ea883-ae59-418b-a1c1-9217046a5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\"y_pred\": y, \"x\": x,}\n",
    "post_conf = conf['model']['post_conf']\n",
    "opt = GlobalEnergyFixer(post_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d965e7d4-0a57-42ef-936a-54093e631ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = opt(input_dict)\n",
    "y_pred = input_dict['y_pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7fa0a-e5b6-4832-b304-666c188cf333",
   "metadata": {},
   "source": [
    "**Check before & after**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0bc350a-6662-49fe-8c7c-11ed6cd9cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_residual_verif(x, y_pred):\n",
    "\n",
    "    state_trans = load_transforms(post_conf, scaler_only=True)\n",
    "    \n",
    "    x = state_trans.inverse_transform_input(x)\n",
    "    y_pred = state_trans.inverse_transform(y_pred)\n",
    "    \n",
    "    N_seconds = 3600 * 6\n",
    "    \n",
    "    T_ind_start = opt.T_ind_start\n",
    "    T_ind_end = opt.T_ind_end\n",
    "    \n",
    "    q_ind_start = opt.q_ind_start\n",
    "    q_ind_end = opt.q_ind_end\n",
    "    \n",
    "    U_ind_start = opt.U_ind_start\n",
    "    U_ind_end = opt.U_ind_end\n",
    "    \n",
    "    V_ind_start = opt.V_ind_start\n",
    "    V_ind_end = opt.V_ind_end\n",
    "    \n",
    "    TOA_solar_ind = opt.TOA_solar_ind\n",
    "    TOA_OLR_ind = opt.TOA_OLR_ind\n",
    "    \n",
    "    surf_solar_ind = opt.surf_solar_ind\n",
    "    surf_LR_ind = opt.surf_LR_ind\n",
    "    \n",
    "    surf_SH_ind = opt.surf_SH_ind\n",
    "    surf_LH_ind = opt.surf_LH_ind\n",
    "\n",
    "    ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "    lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "    lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "    p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "    GPH_surf = torch.from_numpy(ds_physics['geopotential_at_surface'].values)\n",
    "    \n",
    "    core_compute = physics_pressure_level(lon2d, lat2d, p_level, midpoint=False)\n",
    "    \n",
    "    T_input = x[:, T_ind_start:T_ind_end, -1, ...]\n",
    "    q_input = x[:, q_ind_start:q_ind_end, -1, ...]\n",
    "    U_input = x[:, U_ind_start:U_ind_end, -1, ...]\n",
    "    V_input = x[:, V_ind_start:V_ind_end, -1, ...]\n",
    "    \n",
    "    T_pred = y_pred[:, T_ind_start:T_ind_end, 0, ...]\n",
    "    q_pred = y_pred[:, q_ind_start:q_ind_end, 0, ...]\n",
    "    U_pred = y_pred[:, U_ind_start:U_ind_end, 0, ...]\n",
    "    V_pred = y_pred[:, V_ind_start:V_ind_end, 0, ...]\n",
    "            \n",
    "    TOA_solar_pred = y_pred[:, TOA_solar_ind, 0, ...]\n",
    "    TOA_OLR_pred = y_pred[:, TOA_OLR_ind, 0, ...]\n",
    "            \n",
    "    surf_solar_pred = y_pred[:, surf_solar_ind, 0, ...]\n",
    "    surf_LR_pred = y_pred[:, surf_LR_ind, 0, ...]\n",
    "    surf_SH_pred = y_pred[:, surf_SH_ind, 0, ...]\n",
    "    surf_LH_pred = y_pred[:, surf_LH_ind, 0, ...]\n",
    "    \n",
    "    CP_t0 = (1 - q_input) * CP_DRY + q_input * CP_VAPOR\n",
    "    CP_t1 = (1 - q_pred) * CP_DRY + q_pred * CP_VAPOR\n",
    "    \n",
    "    # kinetic energy\n",
    "    ken_t0 = 0.5 * (U_input ** 2 + V_input ** 2)\n",
    "    ken_t1 = 0.5 * (U_pred ** 2 + V_pred ** 2)\n",
    "    \n",
    "    # packing latent heat + potential energy + kinetic energy\n",
    "    E_qgk_t0 = LH_WATER * q_input + GPH_surf + ken_t0\n",
    "    E_qgk_t1 = LH_WATER * q_pred + GPH_surf + ken_t1\n",
    "    \n",
    "    # TOA energy flux\n",
    "    R_T = (TOA_solar_pred + TOA_OLR_pred) / N_seconds\n",
    "    R_T_sum = core_compute.weighted_sum(R_T, axis=(-2, -1))\n",
    "    \n",
    "    # surface net energy flux\n",
    "    F_S = (surf_solar_pred + surf_LR_pred + surf_SH_pred + surf_LH_pred) / N_seconds\n",
    "    F_S_sum = core_compute.weighted_sum(F_S, axis=(-2, -1))\n",
    "\n",
    "    E_level_t0 = CP_t0 * T_input + E_qgk_t0\n",
    "    E_level_t1 = CP_t1 * T_pred + E_qgk_t1\n",
    "\n",
    "    # column integrated total energy\n",
    "    TE_t0 = core_compute.integral(E_level_t0) / GRAVITY\n",
    "    TE_t1 = core_compute.integral(E_level_t1) / GRAVITY\n",
    "    \n",
    "    dTE_dt = (TE_t1 - TE_t0) / N_seconds\n",
    "    \n",
    "    dTE_sum = core_compute.weighted_sum(dTE_dt, axis=(1, 2), keepdims=False)\n",
    "    \n",
    "    delta_dTE_sum = (R_T_sum - F_S_sum) - dTE_sum\n",
    "    \n",
    "    print('Residual to conserve energy budget [Watts]: {}'.format(delta_dTE_sum))\n",
    "    return delta_dTE_sum, dTE_sum, (R_T_sum - F_S_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "615449ee-0474-4994-b8fa-42cb97fcf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve energy budget [Watts]: tensor([-5.1996e+15])\n",
      "Tendency of atmos total energy [Watts]: tensor([-4.9601e+15])\n",
      "Sources and sinks [Watts]: tensor([-1.0160e+16])\n"
     ]
    }
   ],
   "source": [
    "residual_, tendency_, source_sinks_ = energy_residual_verif(x, y_original)\n",
    "print(f'Tendency of atmos total energy [Watts]: {tendency_}')\n",
    "print(f'Sources and sinks [Watts]: {source_sinks_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e03e8f04-4485-49e8-b332-0e76cdec565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual to conserve energy budget [Watts]: tensor([-8.8691e+11])\n",
      "Tendency of atmos total energy [Watts]: tensor([-1.0159e+16])\n",
      "Sources and sinks [Watts]: tensor([-1.0160e+16])\n"
     ]
    }
   ],
   "source": [
    "residual_, tendency_, source_sinks_ = energy_residual_verif(x, y_pred)\n",
    "print(f'Tendency of atmos total energy [Watts]: {tendency_}')\n",
    "print(f'Sources and sinks [Watts]: {source_sinks_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8bc7ec06-4c5b-4f52-a4a0-d55b895d2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = np.array(y_pred)\n",
    "y_original_np = np.array(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10eeafeb-1d94-42e3-8f01-255626ebdf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 hPa largest modified amount: 0.0017015933990478516\n",
      "50.0 hPa largest modified amount: 0.004343904554843903\n",
      "150.0 hPa largest modified amount: 0.004816874861717224\n",
      "200.0 hPa largest modified amount: 0.003679990768432617\n",
      "250.0 hPa largest modified amount: 0.003931522369384766\n",
      "300.0 hPa largest modified amount: 0.005017280578613281\n",
      "400.0 hPa largest modified amount: 0.004933834075927734\n",
      "500.0 hPa largest modified amount: 0.0049419403076171875\n",
      "600.0 hPa largest modified amount: 0.00519561767578125\n",
      "700.0 hPa largest modified amount: 0.0053136348724365234\n",
      "850.0 hPa largest modified amount: 0.004648447036743164\n",
      "925.0 hPa largest modified amount: 0.004318714141845703\n",
      "1000.0 hPa largest modified amount: 0.0041348934173583984\n"
     ]
    }
   ],
   "source": [
    "T_ind_start = opt.T_ind_start\n",
    "T_ind_end = opt.T_ind_end\n",
    "\n",
    "ds_physics = get_forward_data(post_conf['data']['save_loc_physics'])        \n",
    "lon2d = torch.from_numpy(ds_physics['lon2d'].values)\n",
    "lat2d = torch.from_numpy(ds_physics['lat2d'].values)\n",
    "p_level = torch.from_numpy(ds_physics['p_level'].values)\n",
    "\n",
    "for i in range(13):\n",
    "    print(f'{p_level[i]/100} hPa largest modified amount: {np.abs(y_pred_np[0, T_ind_start+i, ...] - y_original_np[0, T_ind_start+i, ...]).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a2c721e-bf49-44fc-8c5f-f5383387b09f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(37):\n",
    "#     plt.figure()\n",
    "#     plt.pcolormesh(y_pred_np[0, T_ind_start+i, 0, ...], cmap=plt.cm.nipy_spectral_r)\n",
    "#     plt.title('level {}'.format(i))\n",
    "#     plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838eff7f-0bd1-4b19-96ae-1b22d18771d4",
   "metadata": {},
   "source": [
    "### Tracer fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d641bb-309e-4925-b30c-59e7e536844d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
