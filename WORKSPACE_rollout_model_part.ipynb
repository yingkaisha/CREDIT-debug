{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb99dd3-1f7c-403f-ac16-f312ba51ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- #\n",
    "# System\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import glob\n",
    "import logging\n",
    "import warnings\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "import multiprocessing as mp\n",
    "\n",
    "# ---------- #\n",
    "# Numerics\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# ---------- #\n",
    "# AI libs\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torchvision import transforms\n",
    "# import wandb\n",
    "\n",
    "# ---------- #\n",
    "# credit\n",
    "from credit.data import Predict_Dataset, concat_and_reshape\n",
    "from credit.models import load_model\n",
    "from credit.transforms import Normalize_ERA5_and_Forcing, load_transforms\n",
    "from credit.seed import seed_everything\n",
    "from credit.pbs import launch_script, launch_script_mpi\n",
    "from credit.pol_lapdiff_filt import Diffusion_and_Pole_Filter\n",
    "from credit.forecast import load_forecasts\n",
    "from credit.distributed import distributed_model_wrapper\n",
    "from credit.models.checkpoint import load_model_state\n",
    "from credit.solar import TOADataLoader\n",
    "from credit.output import split_and_reshape, load_metadata, make_xarray, save_netcdf_increment\n",
    "from torch.utils.data import get_worker_info\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5d0f4f-f072-4eb1-9e11-a8cd7fbc201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = '/glade/u/home/ksha/miles-credit/results/fuxi_norm/model_new.yml'\n",
    "# Read YAML file\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d77431-131b-4852-924c-948a4cb7767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0\n",
    "world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae84dd0-59d2-4c0c-9473-252365756ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer device id from rank\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{rank % torch.cuda.device_count()}\")\n",
    "    torch.cuda.set_device(rank % torch.cuda.device_count())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fda11a7-1efc-4e74-a56d-2e99f1118ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_len = conf[\"data\"][\"history_len\"]\n",
    "transform = load_transforms(conf)\n",
    "\n",
    "if conf[\"data\"][\"scaler_type\"] == 'std_new':\n",
    "    state_transformer = Normalize_ERA5_and_Forcing(conf)\n",
    "# ----------------------------------------------------------------- #\n",
    "# parse varnames and save_locs from config\n",
    "## upper air variables\n",
    "all_ERA_files = sorted(glob.glob(conf[\"data\"][\"save_loc\"]))\n",
    "varname_upper_air = conf['data']['variables']\n",
    "\n",
    "## surface variables\n",
    "if \"save_loc_surface\" in conf[\"data\"]:\n",
    "    surface_files = sorted(glob.glob(conf[\"data\"][\"save_loc_surface\"]))\n",
    "    varname_surface = conf['data']['surface_variables']\n",
    "else:\n",
    "    surface_files = None\n",
    "    varname_surface = None \n",
    "\n",
    "## forcing variables\n",
    "if ('forcing_variables' in conf['data']) and (len(conf['data']['forcing_variables']) > 0):\n",
    "    forcing_files = conf['data']['save_loc_forcing']\n",
    "    varname_forcing = conf['data']['forcing_variables']\n",
    "else:\n",
    "    forcing_files = None\n",
    "    varname_forcing = None\n",
    "\n",
    "## static variables\n",
    "if ('static_variables' in conf['data']) and (len(conf['data']['static_variables']) > 0):\n",
    "    static_files = conf['data']['save_loc_static']\n",
    "    varname_static = conf['data']['static_variables']\n",
    "else:\n",
    "    static_files = None\n",
    "    varname_static = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81457272-7a50-4cbe-af8b-43b76f76c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------- #\\\n",
    "# get dataset\n",
    "dataset = Predict_Dataset(\n",
    "    conf, \n",
    "    varname_upper_air,\n",
    "    varname_surface,\n",
    "    varname_forcing,\n",
    "    varname_static,\n",
    "    filenames=all_ERA_files,\n",
    "    filename_surface=surface_files,\n",
    "    filename_forcing=forcing_files,\n",
    "    filename_static=static_files,\n",
    "    fcst_datetime=load_forecasts(conf),\n",
    "    history_len=history_len,\n",
    "    rank=rank,\n",
    "    world_size=world_size,\n",
    "    transform=transform,\n",
    "    rollout_p=0.0,\n",
    "    which_forecast=None\n",
    ")\n",
    "# setup the dataloder\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f89e8b-60ab-420c-86cf-52c170937fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model(conf, load_weights=True).to(device)\n",
    "\n",
    "if conf[\"trainer\"][\"mode\"] in [\"ddp\", \"fsdp\"]:    \n",
    "    # A new field needs to be added to predict\n",
    "    model = distributed_model_wrapper(conf, model, device)\n",
    "    \n",
    "    if conf[\"trainer\"][\"mode\"] == \"fsdp\":\n",
    "        # Load model weights (if any), an optimizer, scheduler, and gradient scaler\n",
    "        model = load_model_state(conf, model, device)\n",
    "\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfd3f03-61aa-414a-ac82-58901975da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lat/lons from x-array\n",
    "latlons = xr.open_dataset(conf[\"loss\"][\"latitude_weights\"])\n",
    "\n",
    "meta_data = load_metadata(conf)\n",
    "\n",
    "# Set up the diffusion and pole filters\n",
    "if (\n",
    "    \"use_laplace_filter\" in conf[\"predict\"]\n",
    "    and conf[\"predict\"][\"use_laplace_filter\"]\n",
    "):\n",
    "    dpf = Diffusion_and_Pole_Filter(\n",
    "        nlat=conf[\"model\"][\"image_height\"],\n",
    "        nlon=conf[\"model\"][\"image_width\"],\n",
    "        device=device,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d3cefd-3bfc-4ac6-8ee4-5bee94bd935f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     init_datetime_str \u001b[38;5;241m=\u001b[39m init_datetime_str\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mHZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Predict and convert to real space for laplace filter and metrics\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     47\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     48\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m state_transformer\u001b[38;5;241m.\u001b[39minverse_transform(y_pred\u001b[38;5;241m.\u001b[39mcpu())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# Rollout\n",
    "with torch.no_grad():\n",
    "    # forecast count = a constant for each run\n",
    "    forecast_count = 0\n",
    "\n",
    "    # y_pred allocation\n",
    "    y_pred = None\n",
    "    static = None\n",
    "    results = []\n",
    "\n",
    "    # model inference loop\n",
    "    for k, batch in enumerate(data_loader):\n",
    "\n",
    "        # get the datetime and forecasted hours\n",
    "        date_time = batch[\"datetime\"].item()\n",
    "        forecast_hour = batch[\"forecast_hour\"].item()\n",
    "\n",
    "        # initialization on the first forecast hour\n",
    "        if forecast_hour == 1:\n",
    "            # Initialize x and x_surf with the first time step\n",
    "            #x = model.concat_and_reshape(batch[\"x\"], batch[\"x_surf\"]).to(device)\n",
    "            #x = concat_and_reshape(batch[\"x\"], batch[\"x_surf\"]).to(device)\n",
    "\n",
    "            if \"x_surf\" in batch:\n",
    "                # combine x and x_surf\n",
    "                # input: (batch_num, time, var, level, lat, lon), (batch_num, time, var, lat, lon) \n",
    "                # output: (batch_num, var, time, lat, lon), 'x' first and then 'x_surf'\n",
    "                x = concat_and_reshape(batch[\"x\"], batch[\"x_surf\"]).to(device).float()\n",
    "            else:\n",
    "                # no x_surf\n",
    "                x = reshape_only(batch[\"x\"]).to(self.device).float()\n",
    "\n",
    "            # add forcing and static variables\n",
    "            if 'x_forcing_static' in batch:\n",
    "                \n",
    "                # (batch_num, time, var, lat, lon) --> (batch_num, var, time, lat, lon)\n",
    "                x_forcing_batch = batch['x_forcing_static'].to(device).permute(0, 2, 1, 3, 4).float()\n",
    "\n",
    "                # concat on var dimension\n",
    "                x = torch.cat((x, x_forcing_batch), dim=1)\n",
    "            \n",
    "            init_datetime_str = datetime.datetime.utcfromtimestamp(date_time)\n",
    "            init_datetime_str = init_datetime_str.strftime('%Y-%m-%dT%HZ')\n",
    "            \n",
    "        # Predict and convert to real space for laplace filter and metrics\n",
    "        raise\n",
    "        y_pred = model(x)\n",
    "        y_pred = state_transformer.inverse_transform(y_pred.cpu())\n",
    "\n",
    "        if (\"use_laplace_filter\" in conf[\"predict\"] and conf[\"predict\"][\"use_laplace_filter\"]):\n",
    "            y_pred = (\n",
    "                dpf.diff_lap2d_filt(y_pred.to(device).squeeze())\n",
    "                .unsqueeze(0)\n",
    "                .unsqueeze(2)\n",
    "                .cpu()\n",
    "            )\n",
    "\n",
    "        # Save the current forecast hour data in parallel\n",
    "        utc_datetime = datetime.datetime.utcfromtimestamp(date_time) + datetime.timedelta(hours=forecast_hour)\n",
    "\n",
    "        # convert the current step result as x-array\n",
    "        darray_upper_air, darray_single_level = make_xarray(\n",
    "            y_pred,\n",
    "            utc_datetime,\n",
    "            latlons.latitude.values,\n",
    "            latlons.longitude.values,\n",
    "            conf,\n",
    "        )\n",
    "\n",
    "        # Save the current forecast hour data in parallel\n",
    "        result = p.apply_async(\n",
    "            save_netcdf_increment,\n",
    "            (darray_upper_air, darray_single_level, init_datetime_str, forecast_hour, meta_data, conf)\n",
    "        )\n",
    "        results.append(result)\n",
    "\n",
    "        # Update the input\n",
    "        # setup for next iteration, transform to z-space and send to device\n",
    "        y_pred = state_transformer.transform_array(y_pred).to(device)\n",
    "\n",
    "        if history_len == 1:\n",
    "            x = y_pred.detach()\n",
    "        else:\n",
    "            # use multiple past forecast steps as inputs\n",
    "            # static channels will get updated on next pass\n",
    "            static_dim_size = abs(x.shape[1] - y_pred.shape[1])  \n",
    "            # if static_dim_size=0 then :0 gives empty range\n",
    "            x_detach = x[:, :-static_dim_size, 1:].detach() if static_dim_size else x[:, :, 1:].detach()  \n",
    "            x = torch.cat([x_detach, y_pred.detach()], dim=2)\n",
    "\n",
    "        # Explicitly release GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        if batch[\"stop_forecast\"][0]:\n",
    "            # Wait for all processes to finish in order\n",
    "            for result in results:\n",
    "                result.get()\n",
    "\n",
    "            # Now merge all the files into one and delete leftovers\n",
    "            # merge_netcdf_files(init_datetime_str, conf)\n",
    "\n",
    "            # forecast count = a constant for each run\n",
    "            forecast_count += 1\n",
    "\n",
    "            # update lists\n",
    "            results = []\n",
    "\n",
    "            # y_pred allocation\n",
    "            y_pred = None\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "            if distributed:\n",
    "                torch.distributed.barrier()\n",
    "\n",
    "if distributed:\n",
    "    torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ccd54f9-2f0c-4d69-a85e-c03d0b12fba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5151, -0.5148, -0.5146,  ..., -0.5156, -0.5154, -0.5152],\n",
       "         [-0.4601, -0.4599, -0.4595,  ..., -0.4609, -0.4606, -0.4602],\n",
       "         [-0.4083, -0.4081, -0.4079,  ..., -0.4088, -0.4086, -0.4085],\n",
       "         ...,\n",
       "         [-0.6567, -0.6568, -0.6568,  ..., -0.6565, -0.6566, -0.6567],\n",
       "         [-0.6584, -0.6584, -0.6584,  ..., -0.6583, -0.6583, -0.6583],\n",
       "         [-0.6583, -0.6583, -0.6584,  ..., -0.6583, -0.6583, -0.6583]],\n",
       "\n",
       "        [[-0.5215, -0.5213, -0.5212,  ..., -0.5218, -0.5217, -0.5216],\n",
       "         [-0.4651, -0.4650, -0.4648,  ..., -0.4655, -0.4653, -0.4651],\n",
       "         [-0.4081, -0.4081, -0.4080,  ..., -0.4081, -0.4081, -0.4081],\n",
       "         ...,\n",
       "         [-0.6479, -0.6481, -0.6482,  ..., -0.6473, -0.6475, -0.6477],\n",
       "         [-0.6515, -0.6516, -0.6517,  ..., -0.6513, -0.6513, -0.6514],\n",
       "         [-0.6536, -0.6536, -0.6536,  ..., -0.6535, -0.6535, -0.6536]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, -4, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad32f8-0631-4002-ab52-6db8254abddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1221d8c-092e-4f57-a587-ba6ebfefb312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de4c91-9da4-49d1-9dc7-b5b69b66f9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ed6d5-7af8-42e5-a46b-eda53f2c4183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c88d37-b4e3-4912-91e0-8ae3551822fc",
   "metadata": {},
   "source": [
    "### compare old & new rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a07b27-8815-484e-a405-be2bfca0c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'SP' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 't2m' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'V500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'U500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'T500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'Z500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'Q500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n"
     ]
    }
   ],
   "source": [
    "new = xr.open_dataset('/glade/derecho/scratch/ksha/CREDIT/fuxi_norm_new/2018-06-01T00Z/pred_2018-06-01T00Z_002.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3ce744e-164e-49ef-a0cd-7fdfd69c6b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'SP' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 't2m' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'V500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'U500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'T500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'Z500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n",
      "/glade/work/ksha/miniconda3/envs/credit/lib/python3.10/site-packages/xarray/conventions.py:286: SerializationWarning: variable 'Q500' has multiple fill values {9.999e+20, 9.999e+20} defined, decoding all values to NaN.\n",
      "  var = coder.decode(var, name=name)\n"
     ]
    }
   ],
   "source": [
    "old = xr.open_dataset('/glade/derecho/scratch/ksha/CREDIT/fuxi_norm_test/2018-06-01T00Z/pred_2018-06-01T00Z_002.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62bf7539-610b-4021-89a5-c02a32ccc89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40104607"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(new['Z500']) - np.array(old['Z500']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0614d1bf-61bb-41d6-b3dc-10005a29a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[51883.26 , 51883.098, 51883.46 , ..., 51877.56 , 51878.54 ,\n",
       "         51879.797],\n",
       "        [51890.203, 51890.65 , 51890.28 , ..., 51885.215, 51886.035,\n",
       "         51887.37 ],\n",
       "        [51895.32 , 51895.86 , 51895.645, ..., 51890.457, 51891.38 ,\n",
       "         51891.742],\n",
       "        ...,\n",
       "        [50532.99 , 50533.633, 50533.477, ..., 50544.344, 50541.297,\n",
       "         50540.9  ],\n",
       "        [50525.34 , 50526.992, 50525.566, ..., 50535.746, 50533.855,\n",
       "         50532.27 ],\n",
       "        [50501.258, 50500.633, 50504.504, ..., 50509.96 , 50511.91 ,\n",
       "         50511.758]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(new['Z500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db23c858-d46e-4b1b-8e8a-8c98e7e9a8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[51883.438, 51883.258, 51883.61 , ..., 51877.86 , 51878.81 ,\n",
       "         51880.03 ],\n",
       "        [51890.367, 51890.81 , 51890.42 , ..., 51885.51 , 51886.31 ,\n",
       "         51887.613],\n",
       "        [51895.46 , 51895.996, 51895.76 , ..., 51890.734, 51891.625,\n",
       "         51891.96 ],\n",
       "        ...,\n",
       "        [50532.848, 50533.496, 50533.34 , ..., 50544.215, 50541.16 ,\n",
       "         50540.78 ],\n",
       "        [50525.2  , 50526.848, 50525.426, ..., 50535.617, 50533.715,\n",
       "         50532.137],\n",
       "        [50501.11 , 50500.49 , 50504.367, ..., 50509.824, 50511.777,\n",
       "         50511.625]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(old['Z500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d88647-a4fc-4163-b84a-6390e625bb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434481b-1fc2-40a1-9d1d-46982ef517d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31784f97-c273-42e3-83be-b11b17cfcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credit.data import Sample\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aabd5a1-c35e-4dd3-99be-1adebe28c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c478a73-2691-4ae8-8c15-338cc97f6704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ae2aaab-9706-42ba-91ef-dcbee184c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_transformer = Normalize_ERA5_and_Forcing(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99032b2-b973-415d-a99a-4f4926f8032a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce473241-1534-4a0c-859a-eceb0ac1a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = state_transformer.inverse_transform(y_pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "820cde84-c189-4532-b5d6-837670f4faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 67, 1, 640, 1280])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d87d75f-4e44-45b2-a6d3-264595cf9d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 9.6050e+00,  9.6030e+00,  9.5811e+00,  ...,  9.6841e+00,\n",
       "             9.6410e+00,  9.6423e+00],\n",
       "           [ 9.6263e+00,  9.5931e+00,  9.5919e+00,  ...,  9.6613e+00,\n",
       "             9.6555e+00,  9.6297e+00],\n",
       "           [ 9.7909e+00,  9.7778e+00,  9.7666e+00,  ...,  9.8450e+00,\n",
       "             9.8432e+00,  9.8334e+00],\n",
       "           ...,\n",
       "           [ 1.7022e-01,  3.5282e-01,  5.4143e-01,  ...,  5.4510e-02,\n",
       "             1.0519e-01,  1.4594e-01],\n",
       "           [ 2.9755e-01,  4.7897e-01,  6.9006e-01,  ...,  3.1048e-01,\n",
       "             2.8333e-01,  2.2607e-01],\n",
       "           [ 1.0609e-01,  3.1670e-01,  5.3178e-01,  ...,  1.3572e-01,\n",
       "             1.2455e-01,  5.1676e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.2611e+00,  4.2457e+00,  4.2450e+00,  ...,  4.2849e+00,\n",
       "             4.2833e+00,  4.2390e+00],\n",
       "           [ 4.4083e+00,  4.3953e+00,  4.3780e+00,  ...,  4.4362e+00,\n",
       "             4.4175e+00,  4.3946e+00],\n",
       "           [ 4.4866e+00,  4.4929e+00,  4.4759e+00,  ...,  4.5344e+00,\n",
       "             4.5213e+00,  4.5233e+00],\n",
       "           ...,\n",
       "           [-3.4631e+00, -3.4540e+00, -3.5487e+00,  ..., -3.4942e+00,\n",
       "            -3.5571e+00, -3.5442e+00],\n",
       "           [-3.6978e+00, -3.6711e+00, -3.7302e+00,  ..., -3.7283e+00,\n",
       "            -3.7462e+00, -3.7137e+00],\n",
       "           [-3.8344e+00, -3.8189e+00, -3.8602e+00,  ..., -3.8386e+00,\n",
       "            -3.8179e+00, -3.8797e+00]]],\n",
       "\n",
       "\n",
       "         [[[ 4.1664e+00,  4.1688e+00,  4.1532e+00,  ...,  4.2076e+00,\n",
       "             4.1837e+00,  4.1803e+00],\n",
       "           [ 4.2132e+00,  4.2161e+00,  4.2145e+00,  ...,  4.2493e+00,\n",
       "             4.2443e+00,  4.2345e+00],\n",
       "           [ 4.2969e+00,  4.2910e+00,  4.2945e+00,  ...,  4.3309e+00,\n",
       "             4.3330e+00,  4.3323e+00],\n",
       "           ...,\n",
       "           [ 5.8587e+00,  5.8676e+00,  5.9106e+00,  ...,  5.9405e+00,\n",
       "             5.9140e+00,  5.9206e+00],\n",
       "           [ 5.6778e+00,  5.6813e+00,  5.7019e+00,  ...,  5.7697e+00,\n",
       "             5.7556e+00,  5.7781e+00],\n",
       "           [ 5.6048e+00,  5.6631e+00,  5.6585e+00,  ...,  5.6949e+00,\n",
       "             5.7019e+00,  5.7064e+00]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.4940e+02,  2.4941e+02,  2.4941e+02,  ...,  2.4939e+02,\n",
       "             2.4940e+02,  2.4942e+02],\n",
       "           [ 2.4930e+02,  2.4931e+02,  2.4930e+02,  ...,  2.4929e+02,\n",
       "             2.4929e+02,  2.4931e+02],\n",
       "           [ 2.4930e+02,  2.4930e+02,  2.4930e+02,  ...,  2.4929e+02,\n",
       "             2.4929e+02,  2.4930e+02],\n",
       "           ...,\n",
       "           [ 2.3692e+02,  2.3690e+02,  2.3698e+02,  ...,  2.3671e+02,\n",
       "             2.3673e+02,  2.3676e+02],\n",
       "           [ 2.3687e+02,  2.3687e+02,  2.3698e+02,  ...,  2.3664e+02,\n",
       "             2.3669e+02,  2.3670e+02],\n",
       "           [ 2.3687e+02,  2.3690e+02,  2.3690e+02,  ...,  2.3664e+02,\n",
       "             2.3665e+02,  2.3667e+02]]],\n",
       "\n",
       "\n",
       "         [[[ 5.3307e+04,  5.3307e+04,  5.3306e+04,  ...,  5.3307e+04,\n",
       "             5.3307e+04,  5.3308e+04],\n",
       "           [ 5.3297e+04,  5.3297e+04,  5.3296e+04,  ...,  5.3297e+04,\n",
       "             5.3296e+04,  5.3295e+04],\n",
       "           [ 5.3283e+04,  5.3284e+04,  5.3281e+04,  ...,  5.3283e+04,\n",
       "             5.3281e+04,  5.3280e+04],\n",
       "           ...,\n",
       "           [ 5.1009e+04,  5.1024e+04,  5.1022e+04,  ...,  5.0953e+04,\n",
       "             5.0960e+04,  5.0965e+04],\n",
       "           [ 5.0996e+04,  5.1014e+04,  5.1017e+04,  ...,  5.0942e+04,\n",
       "             5.0939e+04,  5.0952e+04],\n",
       "           [ 5.0992e+04,  5.0993e+04,  5.1004e+04,  ...,  5.0922e+04,\n",
       "             5.0922e+04,  5.0931e+04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.4526e-04,  5.4434e-04,  5.4487e-04,  ...,  5.4880e-04,\n",
       "             5.4711e-04,  5.4423e-04],\n",
       "           [ 5.4635e-04,  5.4549e-04,  5.4688e-04,  ...,  5.4866e-04,\n",
       "             5.4790e-04,  5.4682e-04],\n",
       "           [ 5.5487e-04,  5.5425e-04,  5.5409e-04,  ...,  5.5624e-04,\n",
       "             5.5475e-04,  5.5519e-04],\n",
       "           ...,\n",
       "           [ 3.0184e-04,  3.1398e-04,  3.1892e-04,  ...,  3.2617e-04,\n",
       "             3.2722e-04,  3.2497e-04],\n",
       "           [ 3.1588e-04,  3.1566e-04,  3.0542e-04,  ...,  3.2111e-04,\n",
       "             3.2845e-04,  3.2563e-04],\n",
       "           [ 3.2588e-04,  3.2292e-04,  3.1165e-04,  ...,  3.1763e-04,\n",
       "             3.3331e-04,  3.4118e-04]]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8136649-cb33-4976-bf3e-e6a99951a693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123321f-ff81-461d-8634-9323db2db2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
